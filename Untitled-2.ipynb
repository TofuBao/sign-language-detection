{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from glob import glob\n",
    "import random\n",
    "from tensorflow.keras.callbacks import Callback \n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "# 定义需要显示的特定面部关键点编号\n",
    "selected_indices = [\n",
    "    419, 290, 303, 242, 56, 155, 221, 226, 387, 362, 385, 310, 295, 340, 0, 37, 39, 40, 178, 146, 90, 72, \n",
    "    448, 380, 274, 398, 87, 98, 64, 324, 222, 1, 13, 22, 159, 145, 157, 89, \n",
    "    312, 462, 259, 63, 66, 112, 461, 463, 348, 62, 308, 119, 269, 78, 16, 65, 144, 163, \n",
    "    384, 229, 84, 321, 325, 466, 403, 182, 232, 219, 141, 249, 196, 320, 95, \n",
    "    304, 77, 272, 224, 239, 268, 316, 405, 86, 186, \n",
    "    63, 296, 334, 53, 195, 66, 107, 52, 65\n",
    "]\n",
    "\n",
    "# 定义数据类来存储每个关键点的坐标\n",
    "@dataclass\n",
    "class Landmark:\n",
    "    x: float\n",
    "    y: float\n",
    "    z: float\n",
    "\n",
    "# 定义 CustomResults 数据类\n",
    "@dataclass\n",
    "class CustomResults:\n",
    "    face_landmarks: Optional[landmark_pb2.NormalizedLandmarkList] = None\n",
    "    pose_landmarks: Optional[landmark_pb2.NormalizedLandmarkList] = None\n",
    "    left_hand_landmarks: Optional[landmark_pb2.NormalizedLandmarkList] = None\n",
    "    right_hand_landmarks: Optional[landmark_pb2.NormalizedLandmarkList] = None\n",
    "\n",
    "# 提取并过滤面部关键点并生成 NormalizedLandmarkList\n",
    "def create_filtered_face_landmarks(landmarks, indices):\n",
    "    if not landmarks:\n",
    "        return None\n",
    "    filtered_landmarks = [landmarks[idx] for idx in indices]\n",
    "    return landmark_pb2.NormalizedLandmarkList(landmark=filtered_landmarks)\n",
    "# 使用标准的 MediaPipe 绘图方式来绘制关键点（无连接线）\n",
    "def draw_landmarks(image, custom_results):\n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    # 绘制面部关键点（不包含连接线）\n",
    "    if custom_results.face_landmarks:\n",
    "        for idx, landmark in zip(selected_indices, custom_results.face_landmarks.landmark):\n",
    "            x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)  \n",
    "            cv2.putText(image, str(idx), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # 绘制姿势关键点\n",
    "    if custom_results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, custom_results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(88, 22, 88), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(66, 22, 66), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "    # 绘制左手关键点\n",
    "    if custom_results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, custom_results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(100, 22, 200), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(100, 22, 200), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "    # 绘制右手关键点\n",
    "    if custom_results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, custom_results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 90, 0), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(0, 90, 0), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "def extract_keypoints(custom_results):\n",
    "    face = np.array([[lm.x, lm.y, lm.z] for lm in custom_results.face_landmarks.landmark]).flatten() \\\n",
    "        if custom_results.face_landmarks else np.full(90 * 3, np.nan)\n",
    "        \n",
    "    pose = np.array([[lm.x, lm.y, lm.z, lm.visibility] for lm in custom_results.pose_landmarks.landmark]).flatten() \\\n",
    "        if custom_results.pose_landmarks else np.full(33 * 4, np.nan)\n",
    "        \n",
    "    lh = np.array([[lm.x, lm.y, lm.z] for lm in custom_results.left_hand_landmarks.landmark]).flatten() \\\n",
    "        if custom_results.left_hand_landmarks else np.full(21 * 3, np.nan)\n",
    "        \n",
    "    rh = np.array([[lm.x, lm.y, lm.z] for lm in custom_results.right_hand_landmarks.landmark]).flatten() \\\n",
    "        if custom_results.right_hand_landmarks else np.full(21 * 3, np.nan)\n",
    "    \n",
    "    # 合并所有关键点\n",
    "    keypoints = np.concatenate([face, pose, lh, rh])\n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ensure_sequence_shape(sequence):\n",
    "    \"\"\"\n",
    "    确保输入的 sequence 形状为 (seq_len, n_keypoints, 3)。\n",
    "    如果输入是 2D，将其重塑为 3D。\n",
    "    \"\"\"\n",
    "    if sequence.dim() == 2 and sequence.shape[1] % 3 == 0:\n",
    "        n_keypoints = sequence.shape[1] // 3\n",
    "        sequence = sequence.view(sequence.shape[0], n_keypoints, 3)\n",
    "    elif sequence.dim() != 3:\n",
    "        raise ValueError(f\"Expected sequence to have shape (seq_len, n_keypoints, 3), but got {sequence.shape}\")\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def compute_mean_std(X_train):\n",
    "    \"\"\"\n",
    "    计算数据集 X_train 的全局均值和标准差。\n",
    "    \"\"\"\n",
    "    all_keypoints = np.concatenate([sample for sample in X_train], axis=0)\n",
    "    mean = np.nanmean(all_keypoints, axis=0)\n",
    "    std = np.nanstd(all_keypoints, axis=0)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def temporal_resample(sequence, target_length=105, min_scale=0.5, max_scale=1.5):\n",
    "    sequence = ensure_sequence_shape(sequence)\n",
    "    scale = np.random.uniform(min_scale, max_scale)\n",
    "    new_length = int(sequence.shape[0] * scale)\n",
    "\n",
    "    n_keypoints = sequence.shape[1]\n",
    "    sequence = sequence.permute(1, 0, 2).contiguous().view(-1, sequence.shape[0])\n",
    "    resampled_sequence = F.interpolate(sequence.unsqueeze(0), size=new_length, mode='linear', align_corners=False).squeeze(0)\n",
    "    resampled_sequence = resampled_sequence.view(n_keypoints, new_length, 3).permute(1, 0, 2)\n",
    "    final_sequence = F.interpolate(resampled_sequence.permute(1, 2, 0).contiguous().view(-1, resampled_sequence.shape[0]).unsqueeze(0),\n",
    "                                   size=target_length, mode='linear', align_corners=False).squeeze(0)\n",
    "    final_sequence = final_sequence.view(n_keypoints, target_length, 3).permute(1, 0, 2)\n",
    "    return final_sequence\n",
    "\n",
    "\n",
    "def windowed_cutmix(sequence1, sequence2, target_length=105):\n",
    "    sequence1, sequence2 = ensure_sequence_shape(sequence1), ensure_sequence_shape(sequence2)\n",
    "    cut_ratio = np.random.rand()\n",
    "    cut_point1 = int(sequence1.shape[0] * cut_ratio)\n",
    "    cut_point2 = int(sequence2.shape[0] * cut_ratio)\n",
    "    mixed_sequence = torch.cat((sequence1[:cut_point1], sequence2[cut_point2:]), dim=0)\n",
    "    mixed_sequence = mixed_sequence.permute(1, 0, 2).contiguous()\n",
    "    mixed_sequence = mixed_sequence.view(-1, mixed_sequence.shape[1])\n",
    "    final_sequence = F.interpolate(mixed_sequence.unsqueeze(0), size=target_length, mode='linear', align_corners=False).squeeze(0)\n",
    "    final_sequence = final_sequence.view(sequence1.shape[1], target_length, 3).permute(1, 0, 2)\n",
    "    return final_sequence\n",
    "\n",
    "\n",
    "def temporal_shift(sequence, target_length=105, max_shift=10):\n",
    "    sequence = ensure_sequence_shape(sequence)\n",
    "    shift = np.random.randint(-max_shift, max_shift)\n",
    "    shifted_sequence = torch.roll(sequence, shifts=shift, dims=0)\n",
    "    seq_len = shifted_sequence.shape[0]\n",
    "    if seq_len > target_length:\n",
    "        shifted_sequence = F.interpolate(shifted_sequence.permute(1, 2, 0).unsqueeze(0), size=target_length, mode='linear', align_corners=False)\n",
    "        shifted_sequence = shifted_sequence.squeeze(0).permute(2, 0, 1)\n",
    "    elif seq_len < target_length:\n",
    "        padding = torch.zeros((target_length - seq_len, shifted_sequence.shape[1], shifted_sequence.shape[2]), dtype=shifted_sequence.dtype)\n",
    "        shifted_sequence = torch.cat((shifted_sequence, padding), dim=0)\n",
    "    return shifted_sequence\n",
    "\n",
    "\n",
    "def random_keypoint_dropout(sequence, num_points_to_drop=6, num_time_windows=3):\n",
    "    sequence = ensure_sequence_shape(sequence)\n",
    "    seq_len, num_keypoints, _ = sequence.shape\n",
    "    for _ in range(num_time_windows):\n",
    "        start = np.random.randint(0, seq_len)\n",
    "        end = min(seq_len, start + np.random.randint(1, seq_len // num_time_windows))\n",
    "        drop_indices = np.random.choice(num_keypoints, num_points_to_drop, replace=False)\n",
    "        sequence[start:end, drop_indices, :] = 0\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def spatial_mask(sequence, mask_prob=0.3, max_points=10):\n",
    "    sequence = ensure_sequence_shape(sequence)\n",
    "    if np.random.rand() < mask_prob:\n",
    "        num_keypoints = sequence.shape[1]\n",
    "        mask_points = np.random.choice(num_keypoints, max_points, replace=False)\n",
    "        sequence[:, mask_points, :] = 0\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def temporal_mask(sequence, mask_prob=0.3, max_mask_len=10):\n",
    "    sequence = ensure_sequence_shape(sequence)\n",
    "    if np.random.rand() < mask_prob:\n",
    "        seq_len = sequence.shape[0]\n",
    "        mask_len = np.random.randint(1, max_mask_len)\n",
    "        start = np.random.randint(0, seq_len - mask_len)\n",
    "        sequence[start:start + mask_len, :, :] = 0\n",
    "    return sequence\n",
    "\n",
    "def drop_face_or_pose(sequence, drop_face_prob=0.2, drop_pose_prob=0.2, face_indices=None, pose_indices=None):\n",
    "    sequence = ensure_sequence_shape(sequence)  # 确保形状为 (seq_len, n_keypoints, 3)\n",
    "    if np.random.rand() < drop_face_prob and face_indices is not None:\n",
    "        sequence[:, face_indices, :] = 0  # 面部关键点置为 0\n",
    "    if np.random.rand() < drop_pose_prob and pose_indices is not None:\n",
    "        sequence[:, pose_indices, :] = 0  # 姿态关键点置为 0\n",
    "    return sequence\n",
    "\n",
    "def drop_hand_keypoints(sequence, drop_hand_prob=0.05, left_hand_indices=None, right_hand_indices=None):\n",
    "    sequence = ensure_sequence_shape(sequence)  # 确保形状为 (seq_len, n_keypoints, 3)\n",
    "    if np.random.rand() < drop_hand_prob:\n",
    "        if left_hand_indices is not None:\n",
    "            sequence[:, left_hand_indices, :] = 0  # 左手关键点置为 0\n",
    "        if right_hand_indices is not None:\n",
    "            sequence[:, right_hand_indices, :] = 0  # 右手关键点置为 0\n",
    "    return sequence\n",
    "\n",
    "def flip_keypoints(sequence, left_hand_indices, right_hand_indices):\n",
    "    \"\"\"\n",
    "    仅对左右手的关键点进行翻转。\n",
    "\n",
    "    Args:\n",
    "        sequence (torch.Tensor): 形状为 (seq_len, n_keypoints, 3) 的关键点序列。\n",
    "        left_hand_indices (list): 左手关键点索引。\n",
    "        right_hand_indices (list): 右手关键点索引。\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: 翻转后的关键点序列。\n",
    "    \"\"\"\n",
    "    sequence = ensure_sequence_shape(sequence)  # 确保形状为 (seq_len, n_keypoints, 3)\n",
    "\n",
    "    # 翻转 X 坐标\n",
    "    sequence[:, :, 0] = -sequence[:, :, 0]\n",
    "\n",
    "    # 创建副本，用于交换左右手关键点\n",
    "    flipped_sequence = sequence.clone()\n",
    "    for l_idx, r_idx in zip(left_hand_indices, right_hand_indices):\n",
    "        flipped_sequence[:, r_idx, :] = sequence[:, l_idx, :]  # 左手 → 右手\n",
    "        flipped_sequence[:, l_idx, :] = sequence[:, r_idx, :]  # 右手 → 左手\n",
    "\n",
    "    return flipped_sequence\n",
    "def affine_transform(sequence, scale_range=(0.9, 1.1), translation_range=(-0.1, 0.1), rotation_range=(-10, 10)):\n",
    "    sequence = ensure_sequence_shape(sequence)  # 确保形状为 (seq_len, n_keypoints, 3)\n",
    "\n",
    "    # 随机缩放\n",
    "    scale = np.random.uniform(*scale_range)\n",
    "    sequence = sequence * scale\n",
    "\n",
    "    # 随机平移\n",
    "    translation = np.random.uniform(*translation_range, size=(1, sequence.shape[1], sequence.shape[2]))\n",
    "    sequence = sequence + torch.tensor(translation, dtype=sequence.dtype, device=sequence.device)\n",
    "\n",
    "    # 随机旋转（围绕 Z 轴旋转）\n",
    "    angle = np.radians(np.random.uniform(*rotation_range))\n",
    "    rotation_matrix = torch.tensor([\n",
    "        [np.cos(angle), -np.sin(angle), 0],\n",
    "        [np.sin(angle),  np.cos(angle), 0],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=sequence.dtype, device=sequence.device)\n",
    "    sequence = torch.matmul(sequence, rotation_matrix)\n",
    "    return sequence\n",
    "\n",
    "\n",
    "\n",
    "def apply_random_augmentations(sequence, augment_prob=0.5, target_length=105):\n",
    "    \"\"\"\n",
    "    对序列数据应用增强操作，支持未展平的 3D 数据。\n",
    "    sequence 形状: (seq_len, n_keypoints, feature_dim)\n",
    "    \"\"\"\n",
    "    sequence = ensure_sequence_shape(sequence)  # 确保序列为 3D 形状 (seq_len, n_keypoints, 3)\n",
    "    print(f\"Initial sequence shape: {sequence.shape}\")\n",
    "\n",
    "    # 日志记录用于追踪应用的增强操作\n",
    "    logs = []\n",
    "\n",
    "    # 1. 时间增强\n",
    "    if np.random.rand() < augment_prob:\n",
    "        sequence = temporal_resample(sequence, target_length=target_length)\n",
    "        logs.append(\"Applied temporal_resample\")\n",
    "\n",
    "    if np.random.rand() < augment_prob:\n",
    "        sequence = temporal_shift(sequence)\n",
    "        logs.append(\"Applied temporal_shift\")\n",
    "\n",
    "    # 2. 空间增强\n",
    "    if np.random.rand() < augment_prob:\n",
    "        sequence = affine_transform(sequence)\n",
    "        logs.append(\"Applied affine_transform\")\n",
    "\n",
    "    # 3. 遮罩增强\n",
    "    if np.random.rand() < augment_prob:\n",
    "        sequence = drop_face_or_pose(sequence, face_indices=face_indices, pose_indices=pose_indices)\n",
    "        logs.append(\"Applied drop_face_or_pose\")\n",
    "    if np.random.rand() < augment_prob:\n",
    "        sequence = drop_hand_keypoints(sequence, left_hand_indices=left_hand_indices, right_hand_indices=right_hand_indices)\n",
    "        logs.append(\"Applied drop_hand_keypoints\")\n",
    "    if np.random.rand() < augment_prob:\n",
    "        sequence = spatial_mask(sequence)\n",
    "        logs.append(\"Applied spatial_mask\")\n",
    "    if np.random.rand() < augment_prob:\n",
    "        sequence = temporal_mask(sequence)\n",
    "        logs.append(\"Applied temporal_mask\")\n",
    "\n",
    "    # 4. 翻转增强\n",
    "    if np.random.rand() < augment_prob:\n",
    "        sequence = flip_keypoints(sequence, left_hand_indices, right_hand_indices)\n",
    "        logs.append(\"Applied flip_keypoints\")\n",
    "\n",
    "    # 打印日志\n",
    "    if logs:\n",
    "        print(\" | \".join(logs))\n",
    "    sequence = sequence.reshape(sequence.shape[0], -1)  # 展平为 (seq_len, n_keypoints * 3)\n",
    "\n",
    "\n",
    "    print(f\"Final sequence shape: {sequence.shape}\")\n",
    "    return sequence\n",
    "\n",
    "\n",
    "DATA_PATH = \"I:\\\\Ece496\\\\custom_data\\\\preprocess\"\n",
    "target_length = 105  # 设置目标长度\n",
    "batch_size = 8\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 加载数据\n",
    "X = np.load(os.path.join(DATA_PATH, \"X.npy\"), allow_pickle=True)\n",
    "y = np.load(os.path.join(DATA_PATH, \"y.npy\"), allow_pickle=True)\n",
    "X = np.nan_to_num(X, nan=0.0)\n",
    "# 数据集划分\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 保存划分后的数据\n",
    "np.save(os.path.join(DATA_PATH, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(DATA_PATH, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(DATA_PATH, \"X_val.npy\"), X_val)\n",
    "np.save(os.path.join(DATA_PATH, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(DATA_PATH, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(DATA_PATH, \"y_test.npy\"), y_test)\n",
    "\n",
    "# 定义自定义数据集类\n",
    "class ASLDataset(Dataset):\n",
    "    def __init__(self, X, y, global_mean, global_std, augment=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.global_mean = global_mean\n",
    "        self.global_std = global_std\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        # 替换 NaN 为 0\n",
    "        sequence = np.nan_to_num(sequence, nan=0.0)\n",
    "\n",
    "        # 数据标准化\n",
    "        sequence = (sequence - self.global_mean) / self.global_std\n",
    "        sequence = torch.from_numpy(sequence).float()\n",
    "\n",
    "        if self.augment:\n",
    "            sequence = apply_random_augmentations(sequence)\n",
    "\n",
    "\n",
    "        return sequence, torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "global_mean, global_std = compute_mean_std(X_train)\n",
    "# 在3D形状的 (seq_len, n_keypoints, 3) 中，定义关键点索引范围\n",
    "face_indices = list(range(0, 90))            # 面部关键点在 3D 中为 0~89\n",
    "pose_indices = list(range(90, 90 + 33))      # 姿态关键点在 3D 中为 90~122\n",
    "left_hand_indices = list(range(123, 123 + 21))  # 左手关键点在 3D 中为 123~143\n",
    "right_hand_indices = list(range(144, 144 + 21)) # 右手关键点在 3D 中为 144~164global_mean, global_std = compute_mean_std(X_train)\n",
    "train_dataset = ASLDataset(X_train, y_train, global_mean, global_std, augment=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_shift | Applied affine_transform | Applied drop_hand_keypoints | Applied spatial_mask | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied drop_face_or_pose | Applied spatial_mask | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied temporal_shift | Applied affine_transform | Applied drop_face_or_pose | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_shift | Applied affine_transform | Applied drop_hand_keypoints | Applied temporal_mask | Applied flip_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_shift | Applied affine_transform | Applied drop_face_or_pose | Applied spatial_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_shift | Applied drop_face_or_pose | Applied drop_hand_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied temporal_shift | Applied affine_transform | Applied drop_face_or_pose | Applied spatial_mask | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied affine_transform | Applied spatial_mask | Applied temporal_mask | Applied flip_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Batch 1:\n",
      "  Sample 1 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_shift | Applied affine_transform | Applied drop_face_or_pose | Applied spatial_mask | Applied flip_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "  Sample 2 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_shift | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "  Sample 3 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied spatial_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "  Sample 4 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied temporal_shift | Applied drop_face_or_pose\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "  Sample 5 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied affine_transform | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Epoch 1\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied temporal_shift | Applied affine_transform | Applied drop_hand_keypoints | Applied temporal_mask | Applied flip_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied temporal_shift | Applied drop_hand_keypoints | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied affine_transform | Applied drop_hand_keypoints | Applied spatial_mask | Applied temporal_mask | Applied flip_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied affine_transform | Applied drop_hand_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied affine_transform | Applied drop_face_or_pose | Applied spatial_mask | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied affine_transform | Applied drop_face_or_pose | Applied spatial_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied affine_transform | Applied drop_hand_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied affine_transform | Applied drop_face_or_pose | Applied spatial_mask | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "Batch 1:\n",
      "  Sample 1 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied affine_transform | Applied drop_face_or_pose | Applied drop_hand_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "  Sample 2 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied affine_transform | Applied temporal_mask | Applied flip_keypoints\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "  Sample 3 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_resample | Applied temporal_shift | Applied affine_transform | Applied drop_hand_keypoints | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "  Sample 4 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied affine_transform | Applied drop_face_or_pose | Applied drop_hand_keypoints | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n",
      "  Sample 5 enhancements:\n",
      "Initial sequence shape: torch.Size([105, 176, 3])\n",
      "Applied temporal_shift | Applied affine_transform | Applied drop_face_or_pose | Applied drop_hand_keypoints | Applied temporal_mask\n",
      "Final sequence shape: torch.Size([105, 528])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # 单个 epoch 测试\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for batch_idx, (sequences, labels) in enumerate(train_loader):\n",
    "        print(f\"Batch {batch_idx + 1}:\")\n",
    "        for sample_idx, sequence in enumerate(sequences):\n",
    "            if sample_idx < 5:  # 每个批次最多打印前 5 个样本\n",
    "                print(f\"  Sample {sample_idx + 1} enhancements:\")\n",
    "                apply_random_augmentations(sequence)\n",
    "            else:\n",
    "                break  # 只打印 5 条样本\n",
    "        break  # 只打印一个批次，确保代码运行后不输出过多信息\n",
    "    break\n",
    "for epoch in range(1):  # 单个 epoch 测试\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for batch_idx, (sequences, labels) in enumerate(train_loader):\n",
    "        print(f\"Batch {batch_idx + 1}:\")\n",
    "        for sample_idx, sequence in enumerate(sequences):\n",
    "            if sample_idx < 5:  # 每个批次最多打印前 5 个样本\n",
    "                print(f\"  Sample {sample_idx + 1} enhancements:\")\n",
    "                apply_random_augmentations(sequence)\n",
    "            else:\n",
    "                break  # 只打印 5 条样本\n",
    "        break  # 只打印一个批次，确保代码运行后不输出过多信息\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['hello',  'I or me', 'father', 'mother','see u later']\n",
    "label_map = {label: num for num, label in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 使用 'tanh' 激活函数以便利用 cuDNN 优化\n",
    "model.add(LSTM(128, return_sequences=True, activation='tanh', input_shape=(105, 528)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32, activation='tanh'))\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(words), activation='softmax'))\n",
    "\n",
    "# 编译模型，使用 'accuracy' 作为度量指标\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 2.0802 - accuracy: 0.2157   Test loss: 1.5870883464813232, Test accuracy: 0.29411765933036804\n",
      "13/13 [==============================] - 6s 135ms/step - loss: 2.0802 - accuracy: 0.2157 - val_loss: 1.6203 - val_accuracy: 0.2353\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8370 - accuracy: 0.2206   Test loss: 1.6047173738479614, Test accuracy: 0.23529411852359772\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 1.8370 - accuracy: 0.2206 - val_loss: 1.6262 - val_accuracy: 0.1373\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.7176 - accuracy: 0.2230   Test loss: 1.6145646572113037, Test accuracy: 0.19607843458652496\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 1.7176 - accuracy: 0.2230 - val_loss: 1.6096 - val_accuracy: 0.1373\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5992 - accuracy: 0.3162   Test loss: 1.6414796113967896, Test accuracy: 0.09803921729326248\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 1.5992 - accuracy: 0.3162 - val_loss: 1.6380 - val_accuracy: 0.1569\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.6302 - accuracy: 0.2623   Test loss: 1.658940076828003, Test accuracy: 0.19607843458652496\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 1.6302 - accuracy: 0.2623 - val_loss: 1.6350 - val_accuracy: 0.1373\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5553 - accuracy: 0.2917   Test loss: 1.619581937789917, Test accuracy: 0.2549019753932953\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 1.5553 - accuracy: 0.2917 - val_loss: 1.5831 - val_accuracy: 0.3137\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.5379 - accuracy: 0.3431   Test loss: 1.6406776905059814, Test accuracy: 0.1764705926179886\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 1.5379 - accuracy: 0.3431 - val_loss: 1.5672 - val_accuracy: 0.2941\n",
      "Epoch 8/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 1.4377 - accuracy: 0.3984   Test loss: 1.650930404663086, Test accuracy: 0.11764705926179886\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 1.4378 - accuracy: 0.3922 - val_loss: 1.5553 - val_accuracy: 0.2941\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4024 - accuracy: 0.3824   Test loss: 1.7194923162460327, Test accuracy: 0.19607843458652496\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 1.4024 - accuracy: 0.3824 - val_loss: 1.6201 - val_accuracy: 0.2549\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.4008 - accuracy: 0.4069   Test loss: 1.7548950910568237, Test accuracy: 0.1764705926179886\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 1.4008 - accuracy: 0.4069 - val_loss: 1.6186 - val_accuracy: 0.3137\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2788 - accuracy: 0.4436   Test loss: 1.625231385231018, Test accuracy: 0.19607843458652496\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 1.2788 - accuracy: 0.4436 - val_loss: 1.4770 - val_accuracy: 0.3725\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.3036 - accuracy: 0.4559   Test loss: 1.8894267082214355, Test accuracy: 0.19607843458652496\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 1.3036 - accuracy: 0.4559 - val_loss: 1.6984 - val_accuracy: 0.3333\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.2478 - accuracy: 0.4632   Test loss: 1.5139237642288208, Test accuracy: 0.29411765933036804\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 1.2478 - accuracy: 0.4632 - val_loss: 1.4007 - val_accuracy: 0.2941\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1958 - accuracy: 0.4951   Test loss: 1.5988104343414307, Test accuracy: 0.1764705926179886\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 1.1958 - accuracy: 0.4951 - val_loss: 1.4770 - val_accuracy: 0.2157\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.1092 - accuracy: 0.5319   Test loss: 1.5127891302108765, Test accuracy: 0.13725490868091583\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 1.1092 - accuracy: 0.5319 - val_loss: 1.3643 - val_accuracy: 0.1961\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0444 - accuracy: 0.5466   Test loss: 1.4349565505981445, Test accuracy: 0.2549019753932953\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 1.0444 - accuracy: 0.5466 - val_loss: 1.3103 - val_accuracy: 0.2745\n",
      "Epoch 17/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.9631 - accuracy: 0.5911   Test loss: 1.590011715888977, Test accuracy: 0.19607843458652496\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.9752 - accuracy: 0.5882 - val_loss: 1.3850 - val_accuracy: 0.2157\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9295 - accuracy: 0.6127   Test loss: 1.6483454704284668, Test accuracy: 0.13725490868091583\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.9295 - accuracy: 0.6127 - val_loss: 1.4777 - val_accuracy: 0.1961\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9212 - accuracy: 0.6054   Test loss: 1.4537183046340942, Test accuracy: 0.29411765933036804\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.9212 - accuracy: 0.6054 - val_loss: 1.3536 - val_accuracy: 0.2941\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8302 - accuracy: 0.6667   Test loss: 1.272265076637268, Test accuracy: 0.45098039507865906\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 0.8302 - accuracy: 0.6667 - val_loss: 1.2230 - val_accuracy: 0.4314\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.8777 - accuracy: 0.6324   Test loss: 1.783447265625, Test accuracy: 0.13725490868091583\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.8777 - accuracy: 0.6324 - val_loss: 1.6083 - val_accuracy: 0.1569\n",
      "Epoch 22/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.7896 - accuracy: 0.6849   Test loss: 1.597846269607544, Test accuracy: 0.23529411852359772\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.7809 - accuracy: 0.6887 - val_loss: 1.4615 - val_accuracy: 0.2745\n",
      "Epoch 23/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.7979 - accuracy: 0.6901   Test loss: 1.5103442668914795, Test accuracy: 0.3333333432674408\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.8122 - accuracy: 0.6740 - val_loss: 1.1947 - val_accuracy: 0.4902\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.7600 - accuracy: 0.6814   Test loss: 1.155335545539856, Test accuracy: 0.5098039507865906\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.7600 - accuracy: 0.6814 - val_loss: 0.9911 - val_accuracy: 0.5686\n",
      "Epoch 25/100\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.6838 - accuracy: 0.7273   Test loss: 1.476588249206543, Test accuracy: 0.23529411852359772\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.6795 - accuracy: 0.7230 - val_loss: 1.2196 - val_accuracy: 0.3922\n",
      "Epoch 26/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.6376 - accuracy: 0.7448   Test loss: 0.90360426902771, Test accuracy: 0.7450980544090271\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.6372 - accuracy: 0.7426 - val_loss: 0.8086 - val_accuracy: 0.7451\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6524 - accuracy: 0.7500   Test loss: 0.836214542388916, Test accuracy: 0.6078431606292725\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.6524 - accuracy: 0.7500 - val_loss: 0.7223 - val_accuracy: 0.7451\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.7892   Test loss: 0.8161939978599548, Test accuracy: 0.7647058963775635\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.5438 - accuracy: 0.7892 - val_loss: 0.6627 - val_accuracy: 0.7451\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4911 - accuracy: 0.8260   Test loss: 1.0182898044586182, Test accuracy: 0.5686274766921997\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4911 - accuracy: 0.8260 - val_loss: 0.8267 - val_accuracy: 0.7059\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.8407   Test loss: 0.6334245204925537, Test accuracy: 0.8627451062202454\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4266 - accuracy: 0.8407 - val_loss: 0.5585 - val_accuracy: 0.8824\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5784 - accuracy: 0.7819   Test loss: 1.4535324573516846, Test accuracy: 0.3529411852359772\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.5784 - accuracy: 0.7819 - val_loss: 1.4246 - val_accuracy: 0.3529\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.7966   Test loss: 0.6434168219566345, Test accuracy: 0.7843137383460999\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 0.4901 - accuracy: 0.7966 - val_loss: 0.4902 - val_accuracy: 0.8431\n",
      "Epoch 33/100\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.3907 - accuracy: 0.8523   Test loss: 0.7958118319511414, Test accuracy: 0.686274528503418\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.3767 - accuracy: 0.8603 - val_loss: 0.7183 - val_accuracy: 0.7451\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8701   Test loss: 1.0485161542892456, Test accuracy: 0.686274528503418\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.3810 - accuracy: 0.8701 - val_loss: 0.9041 - val_accuracy: 0.6863\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.8211   Test loss: 0.5901749730110168, Test accuracy: 0.7647058963775635\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 0.4421 - accuracy: 0.8211 - val_loss: 0.4205 - val_accuracy: 0.8627\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.8922   Test loss: 0.34388014674186707, Test accuracy: 0.8627451062202454\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.3428 - accuracy: 0.8922 - val_loss: 0.4662 - val_accuracy: 0.7647\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.8995   Test loss: 0.24401260912418365, Test accuracy: 0.9215686321258545\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 0.2879 - accuracy: 0.8995 - val_loss: 0.3130 - val_accuracy: 0.8824\n",
      "Epoch 38/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.2285 - accuracy: 0.9375   Test loss: 0.2763979434967041, Test accuracy: 0.9019607901573181\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.2292 - accuracy: 0.9363 - val_loss: 0.3766 - val_accuracy: 0.8824\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.8824   Test loss: 0.9039820432662964, Test accuracy: 0.6078431606292725\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.2942 - accuracy: 0.8824 - val_loss: 0.5504 - val_accuracy: 0.7843\n",
      "Epoch 40/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.3174 - accuracy: 0.8854   Test loss: 0.6292880773544312, Test accuracy: 0.7058823704719543\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3134 - accuracy: 0.8873 - val_loss: 0.8508 - val_accuracy: 0.7059\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9314   Test loss: 0.30398237705230713, Test accuracy: 0.843137264251709\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.2149 - accuracy: 0.9314 - val_loss: 0.1655 - val_accuracy: 0.9412\n",
      "Epoch 42/100\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.2014 - accuracy: 0.9261   Test loss: 0.17507565021514893, Test accuracy: 0.9411764740943909\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.1954 - accuracy: 0.9314 - val_loss: 0.3491 - val_accuracy: 0.8824\n",
      "Epoch 43/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.2365 - accuracy: 0.9167   Test loss: 0.5308950543403625, Test accuracy: 0.7450980544090271\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.2342 - accuracy: 0.9167 - val_loss: 0.5747 - val_accuracy: 0.8039\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9461   Test loss: 0.43691492080688477, Test accuracy: 0.843137264251709\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.1803 - accuracy: 0.9461 - val_loss: 0.4307 - val_accuracy: 0.8627\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9387   Test loss: 0.6233128309249878, Test accuracy: 0.7843137383460999\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.1741 - accuracy: 0.9387 - val_loss: 1.0840 - val_accuracy: 0.6471\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.9387   Test loss: 0.16771817207336426, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.1940 - accuracy: 0.9387 - val_loss: 0.1403 - val_accuracy: 0.9608\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9681   Test loss: 0.14247681200504303, Test accuracy: 0.9607843160629272\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.1181 - accuracy: 0.9681 - val_loss: 0.2537 - val_accuracy: 0.9020\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9559   Test loss: 0.18016178905963898, Test accuracy: 0.9411764740943909\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.1344 - accuracy: 0.9559 - val_loss: 0.2302 - val_accuracy: 0.9020\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9510   Test loss: 0.8833438754081726, Test accuracy: 0.7254902124404907\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.1450 - accuracy: 0.9510 - val_loss: 0.5581 - val_accuracy: 0.7647\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9583   Test loss: 0.10407298058271408, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.1365 - accuracy: 0.9583 - val_loss: 0.1462 - val_accuracy: 0.9412\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9902   Test loss: 0.148017019033432, Test accuracy: 0.9607843160629272\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.0767 - accuracy: 0.9902 - val_loss: 0.1306 - val_accuracy: 0.9608\n",
      "Epoch 52/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.0755 - accuracy: 0.9818   Test loss: 0.07020439207553864, Test accuracy: 0.9607843160629272\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0731 - accuracy: 0.9828 - val_loss: 0.0832 - val_accuracy: 0.9804\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9681   Test loss: 0.7612638473510742, Test accuracy: 0.7843137383460999\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0943 - accuracy: 0.9681 - val_loss: 1.1206 - val_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9216   Test loss: 0.2676551640033722, Test accuracy: 0.9019607901573181\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.2048 - accuracy: 0.9216 - val_loss: 0.5200 - val_accuracy: 0.8039\n",
      "Epoch 55/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.1211 - accuracy: 0.9688   Test loss: 0.10897879302501678, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.1209 - accuracy: 0.9681 - val_loss: 0.2756 - val_accuracy: 0.9216\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.9632   Test loss: 0.6637017726898193, Test accuracy: 0.8235294222831726\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.1408 - accuracy: 0.9632 - val_loss: 0.8876 - val_accuracy: 0.7255\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9681   Test loss: 0.05907025560736656, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.1092 - accuracy: 0.9681 - val_loss: 0.1046 - val_accuracy: 0.9608\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9877   Test loss: 0.21604213118553162, Test accuracy: 0.9019607901573181\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0653 - accuracy: 0.9877 - val_loss: 0.1957 - val_accuracy: 0.9020\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.9510   Test loss: 0.5413020253181458, Test accuracy: 0.7647058963775635\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.1543 - accuracy: 0.9510 - val_loss: 0.3555 - val_accuracy: 0.8235\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9926   Test loss: 0.07819119840860367, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0494 - accuracy: 0.9926 - val_loss: 0.0629 - val_accuracy: 0.9804\n",
      "Epoch 61/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.0567 - accuracy: 0.9818   Test loss: 0.267730712890625, Test accuracy: 0.8823529481887817\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.0581 - accuracy: 0.9804 - val_loss: 0.5048 - val_accuracy: 0.8039\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9853   Test loss: 0.10635087639093399, Test accuracy: 0.9411764740943909\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.0567 - accuracy: 0.9853 - val_loss: 0.1179 - val_accuracy: 0.9412\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9902   Test loss: 0.20892833173274994, Test accuracy: 0.9019607901573181\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.0482 - accuracy: 0.9902 - val_loss: 0.3434 - val_accuracy: 0.9020\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9902   Test loss: 0.03614972531795502, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.0487 - accuracy: 0.9902 - val_loss: 0.1912 - val_accuracy: 0.9412\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9877   Test loss: 0.03979770466685295, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0613 - val_accuracy: 0.9608\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9877   Test loss: 0.013552817516028881, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0470 - accuracy: 0.9877 - val_loss: 0.1099 - val_accuracy: 0.9804\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9975   Test loss: 0.05429753288626671, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0289 - accuracy: 0.9975 - val_loss: 0.1594 - val_accuracy: 0.9412\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9975   Test loss: 0.005672182887792587, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.0263 - accuracy: 0.9975 - val_loss: 0.0572 - val_accuracy: 0.9608\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9926   Test loss: 0.028498612344264984, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0326 - accuracy: 0.9926 - val_loss: 0.0567 - val_accuracy: 0.9804\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9951   Test loss: 0.4292897582054138, Test accuracy: 0.8627451062202454\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0289 - accuracy: 0.9951 - val_loss: 0.7981 - val_accuracy: 0.8039\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9314   Test loss: 0.8814477324485779, Test accuracy: 0.7254902124404907\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.1847 - accuracy: 0.9314 - val_loss: 1.1467 - val_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.8799   Test loss: 1.8955055475234985, Test accuracy: 0.3529411852359772\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.3219 - accuracy: 0.8799 - val_loss: 1.7971 - val_accuracy: 0.3922\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1958 - accuracy: 0.9314   Test loss: 1.1950573921203613, Test accuracy: 0.7058823704719543\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.1958 - accuracy: 0.9314 - val_loss: 1.8940 - val_accuracy: 0.5294\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9093   Test loss: 0.1762700378894806, Test accuracy: 0.9607843160629272\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.2133 - accuracy: 0.9093 - val_loss: 0.3793 - val_accuracy: 0.8824\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.9583   Test loss: 0.18550565838813782, Test accuracy: 0.9019607901573181\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.1324 - accuracy: 0.9583 - val_loss: 0.2348 - val_accuracy: 0.8824\n",
      "Epoch 76/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.0538 - accuracy: 0.9922   Test loss: 0.05216166004538536, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0519 - accuracy: 0.9926 - val_loss: 0.0844 - val_accuracy: 0.9804\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9828   Test loss: 0.08828767389059067, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0571 - accuracy: 0.9828 - val_loss: 0.1478 - val_accuracy: 0.9608\n",
      "Epoch 78/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.0334 - accuracy: 0.9922   Test loss: 0.23450350761413574, Test accuracy: 0.9019607901573181\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0349 - accuracy: 0.9926 - val_loss: 0.2178 - val_accuracy: 0.9216\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9902   Test loss: 0.26786577701568604, Test accuracy: 0.9411764740943909\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.0472 - accuracy: 0.9902 - val_loss: 0.3906 - val_accuracy: 0.9020\n",
      "Epoch 80/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.0427 - accuracy: 0.9896   Test loss: 0.058893367648124695, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0407 - accuracy: 0.9902 - val_loss: 0.1332 - val_accuracy: 0.9412\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9877   Test loss: 0.020962493494153023, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0411 - accuracy: 0.9877 - val_loss: 0.0757 - val_accuracy: 0.9804\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9877   Test loss: 0.3479618430137634, Test accuracy: 0.8823529481887817\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0481 - accuracy: 0.9877 - val_loss: 0.5107 - val_accuracy: 0.8824\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9877   Test loss: 0.16291047632694244, Test accuracy: 0.9411764740943909\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.0393 - accuracy: 0.9877 - val_loss: 0.3192 - val_accuracy: 0.8824\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9877   Test loss: 0.14632461965084076, Test accuracy: 0.9215686321258545\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.0481 - accuracy: 0.9877 - val_loss: 0.2480 - val_accuracy: 0.9216\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9853   Test loss: 0.07058629393577576, Test accuracy: 0.9607843160629272\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.0474 - accuracy: 0.9853 - val_loss: 0.2435 - val_accuracy: 0.9412\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9926   Test loss: 0.061937183141708374, Test accuracy: 0.9607843160629272\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.0298 - accuracy: 0.9926 - val_loss: 0.2941 - val_accuracy: 0.9216\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9926   Test loss: 0.03452143445611, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0287 - val_accuracy: 0.9804\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9804   Test loss: 0.10934839397668839, Test accuracy: 0.9215686321258545\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.0492 - accuracy: 0.9804 - val_loss: 0.1341 - val_accuracy: 0.9020\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9853   Test loss: 0.013920988887548447, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 0.0563 - val_accuracy: 0.9804\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9853   Test loss: 0.015182794071733952, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0323 - accuracy: 0.9853 - val_loss: 0.0790 - val_accuracy: 0.9412\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9975   Test loss: 0.06987680494785309, Test accuracy: 0.9803921580314636\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0211 - accuracy: 0.9975 - val_loss: 0.2494 - val_accuracy: 0.9608\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9975   Test loss: 0.019728459417819977, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9951   Test loss: 0.013295966200530529, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0208 - accuracy: 0.9951 - val_loss: 0.1779 - val_accuracy: 0.9804\n",
      "Epoch 94/100\n",
      "12/13 [==========================>...] - ETA: 0s - loss: 0.0150 - accuracy: 0.9974   Test loss: 0.0028460125904530287, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.1801 - val_accuracy: 0.9804\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000   Test loss: 0.0017889951122924685, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9804\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000   Test loss: 0.0023428278509527445, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9804\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000   Test loss: 0.002579138847067952, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9804\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000   Test loss: 0.002997483592480421, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9804\n",
      "Epoch 99/100\n",
      "11/13 [========================>.....] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000   Test loss: 0.001805665553547442, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9804\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9951   Test loss: 0.0026520234532654285, Test accuracy: 1.0\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0280 - val_accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "log_dir_with_velocity = os.path.join('Logs', 'with_velocity')\n",
    "tb_callback_with_velocity = TensorBoard(log_dir=log_dir_with_velocity)\n",
    "\n",
    "# 定义 EarlyStopping 回调：当验证损失在 5 个 epoch 后没有改善时停止训练\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# 定义 ReduceLROnPlateau 回调：如果验证损失连续 3 个 epoch 无改善则降低学习率\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# 将回调函数放入列表中\n",
    "callbacks = [tb_callback_with_velocity , early_stopping, reduce_lr]\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, model, X_test, y_test):\n",
    "        super(TestCallback, self).__init__()\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "    \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 这里可以添加评估测试数据集的代码\n",
    "        test_loss, test_acc = self.model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        print(f'   Test loss: {test_loss}, Test accuracy: {test_acc}')\n",
    "        # 可以根据需要添加更多的自定义行为\n",
    "\n",
    "test_callback = TestCallback(model, X_test, y_test)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[tb_callback_with_velocity, test_callback]  # 添加自定义回调\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: I or me_1_alice.mp4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 105, 528), found shape=(None, 105, 1662)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 检查是否达到 105 帧\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sequence) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m105\u001b[39m:\n\u001b[1;32m---> 34\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     35\u001b[0m     label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction)\n\u001b[0;32m     36\u001b[0m     predicted_labels\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filexmmmcttb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\ProgramData\\anaconda3\\envs\\tf2x_clone\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_3\" is incompatible with the layer: expected shape=(None, 105, 528), found shape=(None, 105, 1662)\n"
     ]
    }
   ],
   "source": [
    "TEST_VIDEO_FOLDER = \"I:\\\\Ece496\\\\custom_data\\\\realtime_test\"\n",
    "mp_holistic = mp.solutions.holistic\n",
    "video_files = glob(os.path.join(TEST_VIDEO_FOLDER, \"*.mp4\"))\n",
    "\n",
    "video_files = glob(os.path.join(TEST_VIDEO_FOLDER, \"*.mp4\"))\n",
    "\n",
    "# 处理每个视频\n",
    "for video_file in video_files:\n",
    "    video_name = os.path.basename(video_file)\n",
    "    print(f\"Processing video: {video_name}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    sequence = []  # 存储每帧的关键点\n",
    "    predicted_labels = []  # 存储每帧的预测标签\n",
    "\n",
    "    # 使用 MediaPipe 处理视频\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # 转换颜色空间并处理帧\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(frame_rgb)\n",
    "\n",
    "            # 提取关键点并累加到序列中\n",
    "            keypoints = extract_keypoints(results)\n",
    "            if keypoints is not None:\n",
    "                sequence.append(keypoints)\n",
    "\n",
    "            # 检查是否达到 105 帧\n",
    "            if len(sequence) == 105:\n",
    "                prediction = model.predict(np.expand_dims(sequence, axis=0), verbose=0)[0]\n",
    "                label = np.argmax(prediction)\n",
    "                predicted_labels.append(label)\n",
    "\n",
    "                # 清空 sequence 以便下一段 105 帧\n",
    "                sequence = []\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # 统计出现最多的标签作为最终预测结果\n",
    "    if predicted_labels:\n",
    "        final_prediction = max(set(predicted_labels), key=predicted_labels.count)\n",
    "        print(f\"Video '{video_name}' processed. Final predicted label: {final_prediction} (Action: {actions[final_prediction]})\\n\")\n",
    "    else:\n",
    "        print(f\"Video '{video_name}' processed. No prediction available.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2x_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
