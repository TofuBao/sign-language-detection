{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_PATH = \"I:\\\\Ece496\\\\custom_data\\\\preprocess\"\n",
    "\n",
    "# 加载数据\n",
    "X = np.load(os.path.join(DATA_PATH, \"X.npy\"), allow_pickle=True)\n",
    "y = np.load(os.path.join(DATA_PATH, \"y.npy\"), allow_pickle=True)\n",
    "\n",
    "# 1. 划分数据集（80%训练集，10%验证集，10%测试集）\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 2. 计算训练集的均值和标准差\n",
    "def compute_mean_std(X_train):\n",
    "    all_keypoints = np.concatenate([sample for sample in X_train], axis=0)\n",
    "    mean = np.nanmean(all_keypoints, axis=0)\n",
    "    std = np.nanstd(all_keypoints, axis=0)\n",
    "    return mean, std\n",
    "\n",
    "mean, std = compute_mean_std(X_train)\n",
    "\n",
    "# 保存均值和标准差，方便以后使用\n",
    "np.save(os.path.join(DATA_PATH, \"mean.npy\"), mean)\n",
    "np.save(os.path.join(DATA_PATH, \"std.npy\"), std)\n",
    "\n",
    "# 3. 归一化函数\n",
    "def normalize_sample(sample, mean, std):\n",
    "    return (sample - mean) / std\n",
    "\n",
    "# 4. 使用训练集的均值和标准差对所有数据集进行归一化\n",
    "X_train = [normalize_sample(sample, mean, std) for sample in X_train]\n",
    "X_val = [normalize_sample(sample, mean, std) for sample in X_val]\n",
    "X_test = [normalize_sample(sample, mean, std) for sample in X_test]\n",
    "\n",
    "# 5. 保存分割和归一化后的数据\n",
    "np.save(os.path.join(DATA_PATH, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(DATA_PATH, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(DATA_PATH, \"X_val.npy\"), X_val)\n",
    "np.save(os.path.join(DATA_PATH, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(DATA_PATH, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(DATA_PATH, \"y_test.npy\"), y_test)\n",
    "\n",
    "print(\"数据集划分和标准化完成，并已保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class Preprocessing(nn.Module):\n",
    "    def __init__(self, global_mean, global_std, fill_nan_value=0.0):\n",
    "        super(Preprocessing, self).__init__()\n",
    "        self.global_mean = global_mean\n",
    "        self.global_std = global_std\n",
    "        self.fill_nan_value = fill_nan_value\n",
    "\n",
    "    # 归一化处理\n",
    "    def normalize(self, x):\n",
    "        x = (x - self.global_mean) / self.global_std\n",
    "        return x\n",
    "\n",
    "    # 填充 NaN\n",
    "    def fill_nans(self, x):\n",
    "        x[torch.isnan(x)] = self.fill_nan_value\n",
    "        return x\n",
    "    \n",
    "    # 关键点中心化\n",
    "    def centralize_keypoints(self, keypoints, center_idx=85):\n",
    "        center_x = keypoints[center_idx * 3]\n",
    "        center_y = keypoints[center_idx * 3 + 1]\n",
    "        center_z = keypoints[center_idx * 3 + 2]\n",
    "\n",
    "        # 坐标中心化\n",
    "        keypoints[::3] -= center_x\n",
    "        keypoints[1::3] -= center_y\n",
    "        keypoints[2::3] -= center_z\n",
    "        return keypoints\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将数据形状调整为 (seq_len, n_landmarks, 3)\n",
    "        x = x.reshape(x.shape[0], 3, -1).permute(0, 2, 1)\n",
    "        \n",
    "        # 归一化与 NaN 填充\n",
    "        x = self.normalize(x)\n",
    "        x = self.fill_nans(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_resample(sequence, target_length=105, min_scale=0.5, max_scale=1.5):\n",
    "    # 随机缩放比例\n",
    "    scale = np.random.uniform(min_scale, max_scale)\n",
    "    new_length = int(sequence.shape[0] * scale)\n",
    "    \n",
    "    # 使用插值重采样到新长度\n",
    "    resampled_sequence = F.interpolate(sequence.unsqueeze(0), size=new_length, mode='linear', align_corners=False).squeeze(0)\n",
    "    \n",
    "    # 对重采样后的序列进行裁剪或插值，保证返回长度为 target_length\n",
    "    final_sequence = F.interpolate(resampled_sequence.unsqueeze(0), size=target_length, mode='linear', align_corners=False).squeeze(0)\n",
    "    return final_sequence\n",
    "\n",
    "def temporal_shift(sequence, target_length=105, max_shift=10):\n",
    "    # 随机选择偏移量\n",
    "    shift = np.random.randint(-max_shift, max_shift)\n",
    "    \n",
    "    # 对序列进行滚动\n",
    "    shifted_sequence = torch.roll(sequence, shifts=shift, dims=0)\n",
    "    \n",
    "    # 对滚动后的序列进行裁剪或插值，保证返回长度为 target_length\n",
    "    final_sequence = F.interpolate(shifted_sequence.unsqueeze(0), size=target_length, mode='linear', align_corners=False).squeeze(0)\n",
    "    return final_sequence\n",
    "\n",
    "def windowed_cutmix(sequence1, sequence2, target_length=105):\n",
    "    length1, length2 = sequence1.shape[0], sequence2.shape[0]\n",
    "    \n",
    "    # 随机选择切割比例\n",
    "    cut_ratio = np.random.rand()\n",
    "    cut_point1 = int(length1 * cut_ratio)\n",
    "    cut_point2 = int(length2 * cut_ratio)\n",
    "    \n",
    "    # 生成拼接序列\n",
    "    mixed_sequence = torch.cat((sequence1[:cut_point1], sequence2[cut_point2:]), dim=0)\n",
    "    \n",
    "    # 对拼接后的序列进行裁剪或插值，保证返回长度为 target_length\n",
    "    final_sequence = F.interpolate(mixed_sequence.unsqueeze(0), size=target_length, mode='linear', align_corners=False).squeeze(0)\n",
    "    return final_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flip_keypoints(data, flip_indices):#鼻尖的indice\n",
    "    # 反转 X 坐标\n",
    "    data[:, :, 0] = -data[:, :, 0]\n",
    "    # 根据指定的索引交换左右\n",
    "    flipped_data = data[:, flip_indices]\n",
    "    return flipped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_keypoint_dropout(sequence, num_points_to_drop=6, num_time_windows=3):\n",
    "    seq_len, num_keypoints, _ = sequence.shape\n",
    "\n",
    "    for _ in range(num_time_windows):\n",
    "        # 随机选择时间窗口\n",
    "        start = np.random.randint(0, seq_len)\n",
    "        end = min(seq_len, start + np.random.randint(1, seq_len // num_time_windows))\n",
    "\n",
    "        # 随机选择关键点索引进行遮挡\n",
    "        drop_indices = np.random.choice(num_keypoints, num_points_to_drop, replace=False)\n",
    "        sequence[start:end, drop_indices, :] = 0  # 填充 0，模拟遮挡\n",
    "    \n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_face_or_pose(sequence, drop_face_prob=0.2, drop_pose_prob=0.2, face_indices=None, pose_indices=None):\n",
    "    # 随机决定是否丢弃面部关键点\n",
    "    if np.random.rand() < drop_face_prob and face_indices is not None:\n",
    "        sequence[:, face_indices, :] = 0  # 使用0填充，模拟丢弃\n",
    "\n",
    "    # 随机决定是否丢弃姿态关键点\n",
    "    if np.random.rand() < drop_pose_prob and pose_indices is not None:\n",
    "        sequence[:, pose_indices, :] = 0  # 使用0填充，模拟丢弃\n",
    "    \n",
    "    return sequence\n",
    "def drop_hand_keypoints(sequence, drop_hand_prob=0.05, left_hand_indices=None, right_hand_indices=None):\n",
    "    # 随机决定是否丢弃左右手关键点\n",
    "    if np.random.rand() < drop_hand_prob:\n",
    "        if left_hand_indices is not None:\n",
    "            sequence[:, left_hand_indices, :] = 0  # 左手关键点全置为0\n",
    "        if right_hand_indices is not None:\n",
    "            sequence[:, right_hand_indices, :] = 0  # 右手关键点全置为0\n",
    "            \n",
    "    return sequence\n",
    "def temporal_mask(sequence, mask_prob=0.3, max_mask_len=10):\n",
    "    if np.random.rand() < mask_prob:\n",
    "        seq_len = sequence.shape[0]\n",
    "        mask_len = np.random.randint(1, max_mask_len)\n",
    "        start = np.random.randint(0, seq_len - mask_len)\n",
    "        \n",
    "        # 时间窗口内的关键点置为0\n",
    "        sequence[start:start + mask_len, :, :] = 0\n",
    "    \n",
    "    return sequence\n",
    "def spatial_mask(sequence, mask_prob=0.3, max_points=10):\n",
    "    if np.random.rand() < mask_prob:\n",
    "        num_keypoints = sequence.shape[1]\n",
    "        mask_points = np.random.choice(num_keypoints, max_points, replace=False)\n",
    "        \n",
    "        # 空间上将选中的关键点置为0\n",
    "        sequence[:, mask_points, :] = 0\n",
    "    \n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_transform(sequence, scale_range=(0.9, 1.1), translation_range=(-0.1, 0.1), rotation_range=(-10, 10)):\n",
    "    # 随机缩放\n",
    "    scale = np.random.uniform(*scale_range)\n",
    "    sequence = sequence * scale\n",
    "\n",
    "    # 随机平移\n",
    "    translation = np.random.uniform(*translation_range, size=(1, sequence.shape[1], sequence.shape[2]))\n",
    "    sequence = sequence + translation\n",
    "\n",
    "    # 随机旋转（围绕Z轴旋转）\n",
    "    angle = np.radians(np.random.uniform(*rotation_range))\n",
    "    rotation_matrix = torch.tensor([\n",
    "        [np.cos(angle), -np.sin(angle), 0],\n",
    "        [np.sin(angle),  np.cos(angle), 0],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=sequence.dtype)\n",
    "    \n",
    "    sequence = torch.matmul(sequence, rotation_matrix)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_velocity_and_acceleration(sequence):\n",
    "    # 计算速度（相邻帧之间的差值）\n",
    "    velocity = np.diff(sequence, axis=0, prepend=np.nan)\n",
    "    # 计算加速度（相邻速度之间的差值）\n",
    "    acceleration = np.diff(velocity, axis=0, prepend=np.nan)\n",
    "    \n",
    "    return velocity, acceleration\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2x_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
